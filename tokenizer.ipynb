{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./wizard-of-oz.txt\", encoding=\"utf-8-sig\") as f:\n",
    "    txt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(words): # words: [\"ahoi\", \"matey\", ...\"]\n",
    "    token_ids_array = []\n",
    "    for w in words:\n",
    "        token_ids = []\n",
    "        ptr = 0\n",
    "        while ptr < len(w):\n",
    "            for token, idx in reversed(encode_dict.items()):\n",
    "                if w[ptr:].startswith(token):\n",
    "                    token_ids.append(idx)\n",
    "                    ptr += len(token)\n",
    "                    break\n",
    "\n",
    "        token_ids_array.append(token_ids)\n",
    "    return token_ids_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigram_counts(word_token_ids): # elements: [[1, 4, 22], [2, 44, 0], ...]\n",
    "    bigram_counts = {}\n",
    "\n",
    "    for tokens in word_token_ids:\n",
    "        for a, b in zip(tokens, tokens[1:]):\n",
    "            bigram_counts[(a, b)] = bigram_counts.get((a, b), 0) + 1\n",
    "\n",
    "    return bigram_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(txt)))\n",
    "encode_dict = {c:i for i,c in enumerate(chars)}\n",
    "decode_dict = {i:c for c,i in encode_dict.items()}\n",
    "\n",
    "words = sorted(list(set(txt.split(\" \"))))\n",
    "words.remove(\"\")\n",
    "word_token_ids = tokenize_words(words)\n",
    "\n",
    "for _ in range(1000):\n",
    "    word_token_ids = tokenize_words(words)\n",
    "\n",
    "    counts = bigram_counts(word_token_ids)\n",
    "    most_common_bigram_idx = sorted(counts.items(), key=lambda item: item[1], reverse=True)[0][0]\n",
    "    most_common_bigram = \"\".join([decode_dict[idx] for idx in most_common_bigram_idx])\n",
    "\n",
    "    encode_dict[most_common_bigram] = len(encode_dict)\n",
    "    decode_dict = {i:c for c,i in encode_dict.items()}\n",
    "    print(f\"{most_common_bigram!r}, \", end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D o r o t h y  l i v e d  i n t h e  m i d s t  o f  t h e  g r e a t  K a n s a s  p r a i r i e s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"=> th\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"D o r o th y  l i v e d in the midst of the great Kansas prairies\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
